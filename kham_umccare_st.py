# kham_umccare_app.py
import streamlit as st
import pandas as pd
import numpy as np
import os
from datetime import datetime, date # Import the date object
import re

# Set page configuration (do this ONLY in the main script)
st.set_page_config(
    page_title="Ph√¢n t√≠ch l∆∞·ª£t kh√°m UMC",
    page_icon="üè•",
    layout="wide"
)

# --- Configuration ---
MAX_MONTHS = 12
EXPECTED_CHANNELS = ['B√†n Kh√°m', 'PKH', 'T·ªïng ƒë√†i', 'UMC Care']
EXCLUDE_SPECIALTY_TERMS = ['grand total', 't·ªïng c·ªông', 'total']

# --- Helper Function to Parse Sheet Names ---
# ...(No changes needed here)...
def parse_sheet_name_to_date(sheet_name):
    """Attempts to parse common month/year formats from sheet names."""
    sheet_name_lower = str(sheet_name).lower().strip()
    formats_to_try = [
        "%b-%y", "%b %y", "%B-%y", "%B %y", "%b-%Y", "%b %Y", "%B-%Y", "%B %Y",
        "T%m-%y", "T%m_%y", "T%m-%Y", "T%m_%Y", "thang%m_%y", "thang%m-%y",
        "thang%m_%Y", "thang%m-%Y", "%m/%Y", "%m-%Y", "%Y/%m", "%Y-%m"
    ]
    cleaned_name = re.sub(r'^(sheet|data|thang|t)(\s*|-|_)?', '', sheet_name_lower)
    for fmt in formats_to_try:
        try:
            # Return as Timestamp initially, convert later if needed
            return pd.to_datetime(cleaned_name, format=fmt).replace(day=1)
        except ValueError:
            continue
    # st.warning(f"Kh√¥ng th·ªÉ t·ª± ƒë·ªông nh·∫≠n d·∫°ng th√°ng/nƒÉm t·ª´ t√™n sheet: '{sheet_name}'. B·ªè qua sheet n√†y.") # Reduce noise
    return None

# --- Data Loading Function ---
# ...(No changes needed in the core logic, just ensure it returns Timestamps or None)...
@st.cache_data(ttl=3600)
def load_process_umc_data_monthly(uploaded_file_obj):
    """Loads data assuming each sheet is a month, EXCLUDING 'Grand Total' specialty rows."""
    st.info("ƒêang ƒë·ªçc file Excel...")
    try:
        df_sheets = pd.read_excel(uploaded_file_obj, sheet_name=None)
        if not df_sheets:
            st.error("File Excel kh√¥ng ch·ª©a sheet n√†o.")
            return None

        all_monthly_data = []
        valid_sheets_found = 0
        parsed_sheet_names = [] # Keep track to avoid duplicate warnings

        for sheet_name, raw_data in df_sheets.items():
            month_date = parse_sheet_name_to_date(sheet_name)
            if month_date is None:
                if sheet_name not in parsed_sheet_names: # Show warning only once per name
                    st.warning(f"B·ªè qua sheet '{sheet_name}' do kh√¥ng nh·∫≠n d·∫°ng ƒë∆∞·ª£c ng√†y th√°ng.")
                    parsed_sheet_names.append(sheet_name)
                continue

            if 'Chuy√™n khoa' not in raw_data.columns:
                st.warning(f"Sheet '{sheet_name}' ({month_date.strftime('%b %Y')}) thi·∫øu c·ªôt 'Chuy√™n khoa'. B·ªè qua.")
                continue

            # Exclude Grand Total / Summary Rows
            raw_data['Chuy√™n khoa'] = raw_data['Chuy√™n khoa'].astype(str)
            mask_keep = ~raw_data['Chuy√™n khoa'].str.lower().str.strip().isin(EXCLUDE_SPECIALTY_TERMS)
            data_cleaned = raw_data[mask_keep].copy()
            # num_excluded = len(raw_data) - len(data_cleaned) # Reduce verbose output
            # if num_excluded > 0:
            #      st.write(f"Sheet '{sheet_name}': ƒê√£ lo·∫°i b·ªè {num_excluded} d√≤ng t·ªïng c·ªông.")
            if data_cleaned.empty:
                 st.warning(f"Sheet '{sheet_name}' ({month_date.strftime('%b %Y')}) kh√¥ng c√≤n d·ªØ li·ªáu sau khi lo·∫°i b·ªè d√≤ng t·ªïng c·ªông. B·ªè qua.")
                 continue

            present_channels = [ch for ch in EXPECTED_CHANNELS if ch in data_cleaned.columns]
            # Don't skip if channels are missing, just process what's there + Grand Total later

            cols_to_keep = ['Chuy√™n khoa'] + present_channels
            # Handle potential missing channel columns gracefully when selecting
            cols_to_keep = [col for col in cols_to_keep if col in data_cleaned.columns]
            monthly_df = data_cleaned[cols_to_keep].copy()
            monthly_df['Month'] = month_date

            # Process present channels
            for channel in present_channels: # Only loop through channels actually found
                monthly_df[channel] = pd.to_numeric(monthly_df[channel], errors='coerce').fillna(0).astype(int)

            # Add/Recalculate Grand Total column
            if present_channels: # Only calculate if there were any channels found
                 monthly_df['Grand Total'] = monthly_df[present_channels].sum(axis=1)
            else:
                 monthly_df['Grand Total'] = 0 # Assign 0 if no standard channels were found

            all_monthly_data.append(monthly_df)
            valid_sheets_found += 1

        if not all_monthly_data:
            st.error("Kh√¥ng t√¨m th·∫•y sheet h·ª£p l·ªá n√†o ch·ª©a d·ªØ li·ªáu chuy√™n khoa (sau khi lo·∫°i b·ªè d√≤ng t·ªïng c·ªông).")
            return None

        combined_df = pd.concat(all_monthly_data, ignore_index=True)

        # --- Pivot ---
        pivot_values = [ch for ch in EXPECTED_CHANNELS if ch in combined_df.columns] + ['Grand Total']
        pivot_values = list(set(col for col in pivot_values if col in combined_df.columns)) # Ensure unique and present values

        try:
             # Check for duplicates before pivoting
             duplicates = combined_df[combined_df.duplicated(subset=['Month', 'Chuy√™n khoa'], keep=False)]
             if not duplicates.empty:
                 st.warning("Ph√°t hi·ªán d·ªØ li·ªáu chuy√™n khoa tr√πng l·∫∑p trong c√πng m·ªôt th√°ng. S·∫Ω c·ªông g·ªôp gi√° tr·ªã.")
                 # st.dataframe(duplicates.sort_values(by=['Month', 'Chuy√™n khoa'])) # Optional: show duplicates

             pivoted_df = combined_df.pivot_table(
                 index=['Month', 'Chuy√™n khoa'],
                 values=pivot_values,
                 fill_value=0,
                 aggfunc='sum' # Use sum to handle potential duplicates
             )
        except Exception as pivot_error:
             st.error(f"L·ªói khi t·ªïng h·ª£p d·ªØ li·ªáu: {pivot_error}")
             return None

        pivoted_df = pivoted_df.sort_index()

        # Calculate overall total
        if 'Grand Total' in pivoted_df.columns:
             pivoted_df['Total_Registrations_AllM'] = pivoted_df.groupby(level='Chuy√™n khoa')['Grand Total'].transform('sum')
        else:
             channel_sum_cols = [ch for ch in EXPECTED_CHANNELS if ch in pivoted_df.columns]
             if channel_sum_cols:
                  pivoted_df['Temp_Total'] = pivoted_df[channel_sum_cols].sum(axis=1)
                  pivoted_df['Total_Registrations_AllM'] = pivoted_df.groupby(level='Chuy√™n khoa')['Temp_Total'].transform('sum')
                  if 'Temp_Total' in pivoted_df.columns: del pivoted_df['Temp_Total']
             else:
                  pivoted_df['Total_Registrations_AllM'] = 0

        st.success(f"ƒê√£ x·ª≠ l√Ω th√†nh c√¥ng d·ªØ li·ªáu t·ª´ {valid_sheets_found} sheet.")
        return pivoted_df

    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc ho·∫∑c x·ª≠ l√Ω file Excel: {e}")
        import traceback
        st.error(traceback.format_exc())
        return None

# --- Sidebar ---
st.sidebar.title("T·∫£i & C·∫•u h√¨nh")
uploaded_file = st.sidebar.file_uploader("T·∫£i l√™n file Excel UMC Care (Sheet theo Th√°ng)", type=["xlsx", "xls"])

# Initialize session state
if 'umc_data' not in st.session_state: st.session_state['umc_data'] = None
if 'start_date' not in st.session_state: st.session_state['start_date'] = None
if 'end_date' not in st.session_state: st.session_state['end_date'] = None
if 'min_date' not in st.session_state: st.session_state['min_date'] = None
if 'max_date' not in st.session_state: st.session_state['max_date'] = None

# Load and Store Data in Session State
if uploaded_file is not None:
    data = load_process_umc_data_monthly(uploaded_file) # Use the updated function
    st.session_state['umc_data'] = data
    # Reset dates when new file is uploaded
    if data is not None and not data.empty:
        # Store min/max as Timestamp initially
        min_ts = data.index.get_level_values('Month').min()
        max_ts = data.index.get_level_values('Month').max()
        st.session_state['min_date'] = min_ts
        st.session_state['max_date'] = max_ts
        # Default selection to the full range
        st.session_state['start_date'] = min_ts
        st.session_state['end_date'] = max_ts
    else:
        st.session_state['min_date'] = None
        st.session_state['max_date'] = None
        st.session_state['start_date'] = None
        st.session_state['end_date'] = None
    # Clear uploader buffer maybe? Helps avoid re-processing same file on rerun
    # uploaded_file.seek(0) # Reset buffer - might be needed sometimes


# --- Date Range Selector - WITH FIX ---
if st.session_state['umc_data'] is not None and not st.session_state['umc_data'].empty:
    # Retrieve Timestamps from session state
    min_ts = st.session_state.get('min_date')
    max_ts = st.session_state.get('max_date')
    start_ts = st.session_state.get('start_date')
    end_ts = st.session_state.get('end_date')

    # Convert Timestamps to datetime.date objects for the widget
    min_dt = min_ts.date() if min_ts else date.today() # Provide default if None
    max_dt = max_ts.date() if max_ts else date.today()
    start_dt_val = start_ts.date() if start_ts else min_dt
    end_dt_val = end_ts.date() if end_ts else max_dt

    st.sidebar.markdown("---")
    st.sidebar.subheader("Ch·ªçn Kho·∫£ng Th·ªùi Gian Ph√¢n T√≠ch")
    selected_start_date_obj = st.sidebar.date_input( # Returns a datetime.date object
        "T·ª´ th√°ng", # Changed label slightly
        value=start_dt_val,
        min_value=min_dt,      # PASS datetime.date object
        max_value=max_dt,      # PASS datetime.date object
        key='date_start',
        format="YYYY/MM/DD"    # Use Streamlit's format (displays month/year well usually)
    )

    selected_end_date_obj = st.sidebar.date_input( # Returns a datetime.date object
        "ƒê·∫øn th√°ng", # Changed label slightly
        value=end_dt_val,
        min_value=min_dt,      # PASS datetime.date object
        max_value=max_dt,      # PASS datetime.date object
        key='date_end',
        format="YYYY/MM/DD"    # Use Streamlit's format
    )

    # --- Validation and State Update ---
    # Ensure end date is not before start date
    if selected_end_date_obj < selected_start_date_obj:
        st.sidebar.warning("Ng√†y k·∫øt th√∫c kh√¥ng th·ªÉ tr∆∞·ªõc ng√†y b·∫Øt ƒë·∫ßu.")
        # Don't automatically adjust here, let user fix it, but prevent state update with invalid range
        valid_range = False
    else:
        valid_range = True

    # Convert selected date objects back to first-of-month Timestamps for filtering consistency
    new_start_ts = pd.to_datetime(selected_start_date_obj).replace(day=1)
    new_end_ts = pd.to_datetime(selected_end_date_obj).replace(day=1)

    # Check if the state needs updating (compare Timestamps)
    update_needed = False
    if valid_range:
        if st.session_state.get('start_date') != new_start_ts:
            st.session_state['start_date'] = new_start_ts
            update_needed = True
        if st.session_state.get('end_date') != new_end_ts:
            st.session_state['end_date'] = new_end_ts
            update_needed = True

    # Rerun if state was updated
    if update_needed:
         st.experimental_rerun()

else:
    st.sidebar.info("T·∫£i file d·ªØ li·ªáu l√™n ƒë·ªÉ ch·ªçn kho·∫£ng th·ªùi gian.")


# --- Main Page Content ---
# ...(Same as previous version)...
st.title("üè• Ph√¢n t√≠ch d·ªØ li·ªáu l∆∞·ª£t kh√°m UMC Care (Theo Th√°ng)")
st.markdown("""
Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi ·ª©ng d·ª•ng ph√¢n t√≠ch d·ªØ li·ªáu l∆∞·ª£t ƒëƒÉng k√Ω kh√°m b·ªánh t·∫°i UMC Care.

1.  S·ª≠ d·ª•ng thanh b√™n tr√°i ƒë·ªÉ **t·∫£i l√™n file d·ªØ li·ªáu** c·ªßa b·∫°n (Excel, m·ªói sheet l√† m·ªôt th√°ng, c·ªôt l√† k√™nh).
2.  S·ª≠ d·ª•ng b·ªô ch·ªçn ng√†y b√™n tr√°i ƒë·ªÉ **ch·ªçn kho·∫£ng th·ªùi gian** b·∫°n mu·ªën ph√¢n t√≠ch.
3.  Ch·ªçn c√°c trang ph√¢n t√≠ch (`T·ªïng quan`, `K√™nh ƒêƒÉng K√Ω`,...) t·ª´ thanh ƒëi·ªÅu h∆∞·ªõng b√™n tr√°i.
""")

if st.session_state['umc_data'] is not None:
    start_dt_display = st.session_state.get('start_date')
    end_dt_display = st.session_state.get('end_date')
    if start_dt_display and end_dt_display:
         st.success(f"D·ªØ li·ªáu ƒë√£ s·∫µn s√†ng. Ph√¢n t√≠ch t·ª´ {start_dt_display.strftime('%b %Y')} ƒë·∫øn {end_dt_display.strftime('%b %Y')}. Ch·ªçn m·ªôt trang t·ª´ thanh b√™n.")
         st.dataframe(st.session_state['umc_data'].head())
    else:
         st.error("Kh√¥ng th·ªÉ x√°c ƒë·ªãnh kho·∫£ng th·ªùi gian t·ª´ d·ªØ li·ªáu ƒë√£ t·∫£i.")
else:
     st.warning("Ch∆∞a c√≥ d·ªØ li·ªáu ƒë·ªÉ hi·ªÉn th·ªã. Vui l√≤ng t·∫£i file l√™n.")

st.sidebar.success("Ch·ªçn m·ªôt trang ph√¢n t√≠ch ·ªü tr√™n.")